{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "dQXd0vxFAQei"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABln2Sq0_WSy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#visualization libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8-dark')\n",
        "#image processing libraries\n",
        "import glob as gb\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import  ImageDataGenerator,load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing import image\n",
        "#Models builidng essentials libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential,Model, load_model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Dropout, BatchNormalization, Flatten\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
        "#spliting the dataset into train, validation and training library\n",
        "from sklearn.model_selection import train_test_split\n",
        "#to check the time for execution\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ],
      "metadata": {
        "id": "eFMUm7qk_mUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qHNNO75ADGnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Specie_finder_5C.zip\""
      ],
      "metadata": {
        "id": "t2vwEPqU_qZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting the basic stuff"
      ],
      "metadata": {
        "id": "85-U5L3_Ae3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'Specie_finder_5C'\n",
        "# classes = ['char', 'perch', 'tilapia', 'trout', 'pikeperch']\n",
        "classes = os.listdir(data_dir)\n",
        "img_height, img_width = 224, 224\n",
        "batch_size = 16\n",
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "8PnoxsWB_9Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def load_and_preprocess_image(img_path):\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    img = img.resize((img_height, img_width))\n",
        "    img = np.array(img) / 255.0\n",
        "    return img\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        for class_idx, class_name in enumerate(classes):\n",
        "            class_folder = os.path.join(folder, class_name)\n",
        "            for filename in os.listdir(class_folder):\n",
        "                img_path = os.path.join(class_folder, filename)\n",
        "                img = executor.submit(load_and_preprocess_image, img_path)\n",
        "                images.append(img)\n",
        "                labels.append(class_idx)\n",
        "\n",
        "    images = [img.result() for img in images]  # Retrieve results from threads\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load and preprocess the images\n",
        "images, labels = load_images_from_folder(data_dir)\n",
        "\n",
        "# Convert labels to one-hot encoded vectors\n",
        "num_classes = len(classes)\n",
        "labels_one_hot = tf.keras.utils.to_categorical(labels, num_classes)\n"
      ],
      "metadata": {
        "id": "q4HPzIaRf6Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Dataset"
      ],
      "metadata": {
        "id": "qfvvi4s1AkII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for class_idx, class_name in enumerate(classes):\n",
        "        class_folder = os.path.join(folder, class_name)\n",
        "        for filename in os.listdir(class_folder):\n",
        "            img_path = os.path.join(class_folder, filename)\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            img = img.resize((img_height, img_width))\n",
        "            img = np.array(img) / 255.0\n",
        "            images.append(img)\n",
        "            labels.append(class_idx)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load and preprocess the images\n",
        "images, labels = load_images_from_folder(data_dir)\n",
        "\n",
        "# Convert labels to one-hot encoded vectors\n",
        "num_classes = len(classes)\n",
        "labels_one_hot = tf.keras.utils.to_categorical(labels, num_classes)\n"
      ],
      "metadata": {
        "id": "QComvlbEAjhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(images.shape)"
      ],
      "metadata": {
        "id": "Fh09U6qDHp_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis on the Fish Image Data"
      ],
      "metadata": {
        "id": "MmCZQxyQDtTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ploting the History Plot for trained model**"
      ],
      "metadata": {
        "id": "oHugCf2aWa02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "  fig, axs = plt.subplots(2)\n",
        "\n",
        "  #create accuracy subplot\n",
        "  axs[0].plot(history.history[\"accuracy\"], label = 'train accuracy')\n",
        "  axs[0].plot(history.history[\"val_accuracy\"], label= 'test accuracy')\n",
        "  axs[0].set_ylabel(\"Accuracy\")\n",
        "  axs[0].legend(loc='lower right')\n",
        "  axs[0].set_title(\"Accuracy eval\")\n",
        "\n",
        "\n",
        "  #create loss subplot\n",
        "  axs[1].plot(history.history[\"loss\"], label = 'train error')\n",
        "  axs[1].plot(history.history[\"val_loss\"], label = 'test error')\n",
        "  axs[1].set_ylabel(\"Error\")\n",
        "  axs[1].set_xlabel(\"Epochs\")\n",
        "  axs[1].legend(loc='upper right')\n",
        "  axs[1].set_title(\"Error eval\")\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Ki7N6cjwWab4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To check the Number of images in each class**"
      ],
      "metadata": {
        "id": "Z-5DGxMYMU5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_path=[] # To include the full path of each image\n",
        "for img_path in os.listdir(data_dir):\n",
        "    if img_path in ['Segmentation_example_script.m','README.txt','license.txt'] :\n",
        "        continue\n",
        "    # print(img_path)\n",
        "\n",
        "    all_data=gb.glob(pathname=data_dir+'/'+img_path+'/*.*')\n",
        "    print(' found {} in {} '.format(len(all_data),img_path))\n",
        "    all_path.extend(all_data)"
      ],
      "metadata": {
        "id": "ZeHB33LOAAmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(all_path))"
      ],
      "metadata": {
        "id": "5JUvLT2cHeSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the Dataframe from images**"
      ],
      "metadata": {
        "id": "GTO1HCrNHJvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_df = pd.DataFrame({'FilePath': all_path})\n",
        "images_df['Label'] = images_df['FilePath'].apply(lambda x: x.split('/')[-2])\n",
        "pd.options.display.max_colwidth = 200\n",
        "\n",
        "\n",
        "images_df = images_df.sample(frac=1).reset_index(drop=True)\n",
        "images_df.head(5)"
      ],
      "metadata": {
        "id": "wx8C7wXOGCq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check the Distribution of data for each class**"
      ],
      "metadata": {
        "id": "bDPtqPe9MFbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "sns.countplot(data=images_df,x='Label')\n",
        "plt.xticks(rotation = 60)\n",
        "plt.subplot(1,2,2)\n",
        "plt.pie(x=images_df['Label'].value_counts().values,labels=images_df['Label'].value_counts().index,autopct='%1.1f%%')\n",
        "plt.suptitle('Distribution of each class in data',size=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1UnmG2rKLoXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Displaying the some pictures from the image dataset**"
      ],
      "metadata": {
        "id": "7w2fXKiTNr5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(15,7), subplot_kw={'xticks':[], 'yticks':[]})\n",
        "for i, ax in enumerate(axes.flat):\n",
        "  ax.imshow(plt.imread(images_df.FilePath[i]))\n",
        "  ax.set_title(images_df.Label[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "99Ut9uYtL4Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting the Image Dataset"
      ],
      "metadata": {
        "id": "RLH_xACuURMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(images, labels_one_hot, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "gpMEAe82UQ1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1st Experiment Setting the Base of VGG16 apply on the loaded images**"
      ],
      "metadata": {
        "id": "SZAlwN-WOxJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_pretrained_model = VGG16(\n",
        "    input_shape=(img_height, img_width, 3),\n",
        "    include_top = False,\n",
        "    weights = 'imagenet',\n",
        "    pooling='avg'\n",
        ")\n",
        "\n",
        "vgg_pretrained_model.trainable = False"
      ],
      "metadata": {
        "id": "Qa1k1TSkNWqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Early Stopping, Reduces the Regularization term, and saving the best model weights"
      ],
      "metadata": {
        "id": "uIWPpEhVQ4KO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping =EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n",
        "\n",
        "reduce_lr=ReduceLROnPlateau(monitor='val_loss',patience=2,verbose=0,factor=0.1)\n",
        "\n",
        "model_check_point=ModelCheckpoint(monitor='val_accuracy',filepath='/content/drive/MyDrive/kanwal_work/vgg16_fish/bestmodel.h5',save_best_only=True,verbose=True)"
      ],
      "metadata": {
        "id": "jwCk1imuPWSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = vgg_pretrained_model.input\n",
        "\n",
        "x = Dense(128,activation='relu')(vgg_pretrained_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "outputs = Dense(len(classes), activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=num_epochs,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=[early_stopping, reduce_lr, model_check_point],\n",
        "    validation_split=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "uoOSWebKQo9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot the History of the VGG image Model**"
      ],
      "metadata": {
        "id": "0mmEnuw_MMGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "id": "_zUKevyRU62h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_load_model = load_model('/content/drive/MyDrive/kanwal_work/vgg16_fish/bestmodel.h5')"
      ],
      "metadata": {
        "id": "aaqGwTGHWnYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = vgg_load_model.evaluate(X_test,y_test)\n",
        "print(f'Testing Accuracy : {acc*100:.2f}')\n",
        "loss_val, acc_val = vgg_load_model.evaluate(X_val, y_val)\n",
        "print(f'validation Accuracy : {acc_val*100:.2f}')\n",
        "loss_tr, acc_tr = vgg_load_model.evaluate(X_train, y_train)\n",
        "print(f'Training Accuracy : {acc_tr*100:.2f}')\n"
      ],
      "metadata": {
        "id": "KurXPupTXGgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "id": "u_BNQYfFkaOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2nd Experiment Training VGG16 using the another approach DataFrame**"
      ],
      "metadata": {
        "id": "Oo0x5N6jyAQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spliting the Dataset into Training and Testing**"
      ],
      "metadata": {
        "id": "pW6-MHWSLqvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_df,testing_df=train_test_split(images_df,test_size=0.1,shuffle=True,random_state=1)\n",
        "\n",
        "print('The dimension of training data :',training_df.shape)\n",
        "print('The dimension of testing data :',testing_df.shape)"
      ],
      "metadata": {
        "id": "mB4_s2UoXNU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spliting the dataset into testing and training**"
      ],
      "metadata": {
        "id": "LQRYXp5rL4Ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_generator=ImageDataGenerator(\n",
        "                                     tf.keras.applications.vgg16.preprocess_input,\n",
        "                                       validation_split = 0.1\n",
        "\n",
        "                                      )\n",
        "\n",
        "testing_generator=ImageDataGenerator(\n",
        "                                    tf.keras.applications.vgg16.preprocess_input\n",
        "                                    )"
      ],
      "metadata": {
        "id": "AE0iSFLZ0eQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the Dataset into Training, validation and Testing**"
      ],
      "metadata": {
        "id": "k3lsuZ-KL_OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_images=training_generator.flow_from_dataframe(\n",
        "\n",
        "    dataframe=training_df,\n",
        "    x_col='FilePath',\n",
        "    y_col='Label',\n",
        "    class_mode='categorical',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='training',\n",
        "\n",
        "\n",
        "\n",
        ")\n",
        "validation_images=training_generator.flow_from_dataframe(\n",
        "\n",
        "\n",
        "    dataframe=training_df,\n",
        "    x_col='FilePath',\n",
        "    y_col='Label',\n",
        "    class_mode='categorical',\n",
        "    target_size=(224,224),\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='validation'\n",
        "\n",
        ")\n",
        "testing_images=testing_generator.flow_from_dataframe(\n",
        "\n",
        "\n",
        "    dataframe=testing_df,\n",
        "    x_col='FilePath',\n",
        "    y_col='Label',\n",
        "    class_mode='categorical',\n",
        "    target_size=(224,224),\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        ")\n"
      ],
      "metadata": {
        "id": "REOZb0Z90VeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_pretrained_model = VGG16(\n",
        "    input_shape=(img_height, img_width, 3),\n",
        "    include_top = False,\n",
        "    weights = 'imagenet',\n",
        "    pooling='avg'\n",
        ")\n",
        "\n",
        "vgg_pretrained_model.trainable = False"
      ],
      "metadata": {
        "id": "NXS2Fb9SyYh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "class CustomEarlyStopping(Callback):\n",
        "    def __init__(self, target_accuracy):\n",
        "        super(CustomEarlyStopping, self).__init__()\n",
        "        self.target_accuracy = target_accuracy\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs['accuracy'] >= self.target_accuracy:\n",
        "            print(f\"\\nTraining accuracy reached {self.target_accuracy*100}%.\\nTraining stopped.\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "custom_early_stopping = CustomEarlyStopping(target_accuracy=0.92)"
      ],
      "metadata": {
        "id": "pFI_kYAAxPwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "inputs = vgg_pretrained_model.input\n",
        "\n",
        "x = Dense(128,activation='relu')(vgg_pretrained_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "\n",
        "outputs = Dense(len(classes), activation='softmax')(x)\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    training_images,\n",
        "    validation_data=validation_images,\n",
        "    epochs=100,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=[custom_early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "bQmlpxK9zCHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"/content/drive/MyDrive/kanwal_work/fish_specie_5C_v2.h5\")"
      ],
      "metadata": {
        "id": "D0jNktOjpTga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "id": "V4c1hxcHzIlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(plt.style.available)\n"
      ],
      "metadata": {
        "id": "QYufzMjr68Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the VGG16 Model (DataFram)**"
      ],
      "metadata": {
        "id": "Kc8gjVd3LTFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_dataframe_model = load_model('/content/drive/MyDrive/kanwal_work/fish_specie_5C_v2.h5')"
      ],
      "metadata": {
        "id": "RZMp9j0r7O5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation of VGG16 Model**"
      ],
      "metadata": {
        "id": "VDHOtzQ9LZ0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Eval = vgg_dataframe_model.evaluate(testing_images)\n",
        "print(\"Test Accuracy: {:.2f}%\".format(Eval[1] * 100))\n",
        "print(\"Test Loss: {:.5f}\".format(Eval[0]))"
      ],
      "metadata": {
        "id": "87rsKC3E8F0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary Model of the VGG16 using DataFrame Approach**"
      ],
      "metadata": {
        "id": "fZoTQ8e1LJPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "ulSNYGzo9Jr9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}